import os
import csv
import tempfile
from dotenv import load_dotenv

from ms_client import get_stock_all
from ozon_client import get_products_state_by_offer_ids, update_stocks
from ozon_client2 import update_stocks as update_stocks_ozon2

try:
    from notifier import send_telegram_message, send_telegram_document
except ImportError:
    def send_telegram_message(text: str) -> bool:
        print("Telegram notifier –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω:", text)
        return False

    def send_telegram_document(file_path: str, caption: str = "") -> bool:
        print("Telegram notifier –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ñ–∞–π–ª–∞:", file_path)
        return False


load_dotenv()

DRY_RUN = os.getenv("DRY_RUN", "true").lower() == "true"

IGNORE_STOCK_OFFERS = set(
    offer.strip() for offer in os.getenv("IGNORE_STOCK_OFFERS", "").split(",") if offer.strip()
)


# ---------------------
#  –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ê–†–¢–ò–ö–£–õ–û–í
# ---------------------

# –ó–∞–º–µ–Ω–∞ —Ä—É—Å—Å–∫–∏—Ö –±—É–∫–≤ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ
ARTICLE_TRANSLATION = str.maketrans({
    "–ê": "A", "–í": "B", "–ï": "E", "–ö": "K", "–ú": "M",
    "–ù": "H", "–û": "O", "–†": "P", "–°": "C", "–¢": "T",
    "–£": "Y", "–•": "X",

    "–∞": "a", "–≤": "b", "–µ": "e", "–∫": "k", "–º": "m",
    "–Ω": "h", "–æ": "o", "—Ä": "p", "—Å": "c", "—Ç": "t",
    "—É": "y", "—Ö": "x",
})

def normalize_article(article: str) -> str:
    """–ü—Ä–∏–≤–æ–¥–∏–º –∞—Ä—Ç–∏–∫—É–ª–∞ –∫ –µ–¥–∏–Ω–æ–π —Ä–∞—Å–∫–ª–∞–¥–∫–µ."""
    return article.translate(ARTICLE_TRANSLATION).strip()


# ---------------------
#  –°–ö–õ–ê–î–´
# ---------------------

def _parse_warehouse_map() -> dict[str, int]:
    warehouse_map: dict[str, int] = {}

    raw_map = os.getenv("OZON_WAREHOUSE_MAP", "").strip()
    if raw_map:
        for pair in raw_map.split(","):
            pair = pair.strip()
            if not pair:
                continue
            try:
                ms_store_id, ozon_wh_id = pair.split(":", 1)
                warehouse_map[ms_store_id.strip()] = int(ozon_wh_id.strip())
            except Exception:
                print(f"[WARN] –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–∞—Ä—ã: {pair}")

    if not warehouse_map:
        ms_old = os.getenv("MS_OZON_STORE_ID")
        wh_old = os.getenv("OZON_WAREHOUSE_ID")
        if ms_old and wh_old:
            warehouse_map[ms_old] = int(wh_old)

    if not warehouse_map:
        raise RuntimeError("–ù–µ –∑–∞–¥–∞–Ω—ã —Å–∫–ª–∞–¥—ã. –£–∫–∞–∂–∏ OZON_WAREHOUSE_MAP –≤ .env")

    print("[STOCK] –ö–∞—Ä—Ç–∞ —Å–∫–ª–∞–¥–æ–≤:")
    for ms_id, wh_id in warehouse_map.items():
        print(f"  MS store {ms_id} ‚Üí Ozon warehouse_id {wh_id}")

    return warehouse_map


WAREHOUSE_MAP = _parse_warehouse_map()


# ---------------------
#  –ß–¢–ï–ù–ò–ï –û–°–¢–ê–¢–ö–û–í –ò–ó –ú–°
# ---------------------

def _fetch_ms_stock_rows_for_store(ms_store_id: str, limit: int = 1000) -> list[dict]:
    rows: list[dict] = []
    offset = 0

    while True:
        data = get_stock_all(limit=limit, offset=offset, store_id=ms_store_id)
        batch = data.get("rows", [])

        if not batch:
            break

        rows.extend(batch)

        if len(batch) < limit:
            break

        offset += limit

    return rows


# ---------------------
#  –§–ò–õ–¨–¢–†–ê–¶–ò–Ø + –ù–û–†–ú–ê –ê–†–¢–ò–ö–£–õ–û–í
# ---------------------

def _is_archive_or_deleted(row: dict) -> bool:
    """–ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–≤–∞—Ä—ã ¬´–í –∞—Ä—Ö–∏–≤–µ¬ª –∏–ª–∏ ¬´–°–Ω—è—Ç—ã —Å –ø—Ä–æ–¥–∞–∂–∏¬ª."""
    assortment = row.get("assortment") or {}
    a_state = (assortment.get("archived") or False)
    status = (assortment.get("status") or "").lower().strip()

    return (
        a_state is True
        or status in ("archived", "removed", "discontinued", "snyat_s_prodazhi", "—Å–Ω—è—Ç —Å –ø—Ä–æ–¥–∞–∂–∏", "—Å–Ω—è—Ç —Å –ø—Ä–æ–¥–∞–∂")
    )


def build_ozon_stocks_from_ms() -> tuple[list[dict], int, list[dict]]:
    candidates: list[tuple[str, int, int]] = []
    names_by_article: dict[str, str] = {}

    for ms_store_id, ozon_wh_id in WAREHOUSE_MAP.items():
        print(f"[STOCK] –ß–∏—Ç–∞–µ–º –æ—Å—Ç–∞—Ç–∫–∏ –∏–∑ –ú–°: store_id={ms_store_id} ‚Üí Ozon warehouse_id={ozon_wh_id}")

        rows = _fetch_ms_stock_rows_for_store(ms_store_id)

        for row in rows:

            # ‚ùå –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—Ä—Ö–∏–≤ / —Å–Ω—è—Ç—ã —Å –ø—Ä–æ–¥–∞–∂–∏
            if _is_archive_or_deleted(row):
                continue

            article_raw = row.get("article")
            if not article_raw:
                continue

            # ‚úîÔ∏è –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞—Ä—Ç–∏–∫—É–ª
            article = normalize_article(article_raw)

            if article in IGNORE_STOCK_OFFERS:
                continue

            name = (
                row.get("name")
                or (row.get("assortment") or {}).get("name")
                or ""
            )

            stock_raw = row.get("stock", 0)
            try:
                stock_int = int(stock_raw)
            except Exception:
                stock_int = 0

            if stock_int < 0:
                stock_int = 0

            candidates.append((article, stock_int, ozon_wh_id))

            if article not in names_by_article and name:
                names_by_article[article] = name

    if not candidates:
        return [], 0, []

    # ============ –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –°–¢–ê–¢–£–°–ê–ú OZON (–æ–±–∞ –∫–∞–±–∏–Ω–µ—Ç–∞) ============

    # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ offer_id
    offer_ids = [c[0] for c in candidates]

    # —Å—Ç–∞—Ç—É—Å—ã –ø–µ—Ä–≤–æ–≥–æ –∫–∞–±–∏–Ω–µ—Ç–∞
    from ozon_client import get_products_state_by_offer_ids as ozon1_states_fetch
    ozon1_states = ozon1_states_fetch(offer_ids) or []

    # —Å—Ç–∞—Ç—É—Å—ã –≤—Ç–æ—Ä–æ–≥–æ –∫–∞–±–∏–Ω–µ—Ç–∞
    from ozon_client2 import get_products_state_by_offer_ids as ozon2_states_fetch
    ozon2_states = ozon2_states_fetch(offer_ids) or []

    # –°–æ–∑–¥–∞—ë–º –∫–∞—Ä—Ç—É offer_id ‚Üí state (–±–µ—Ä—ë–º —Å–∞–º–æ–µ ¬´–∂—ë—Å—Ç–∫–æ–µ¬ª —Å–æ—Å—Ç–æ—è–Ω–∏–µ)
    status_map = {}

    def merge_state(offer_id, state):
        if not offer_id or not state:
            return
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: archived > disabled > unavailable > available
        prior = {
            "archived": 3,
            "disabled": 2,
            "unavailable": 1,
            "available": 0,
            None: -1,
        }
        prev = status_map.get(offer_id)
        if prev is None or prior[state] > prior.get(prev, -1):
            status_map[offer_id] = state

    for item in ozon1_states:
        merge_state(item.get("offer_id"), item.get("state"))

    for item in ozon2_states:
        merge_state(item.get("offer_id"), item.get("state"))

    # –¢–µ–ø–µ—Ä—å —Ñ–∏–ª—å—Ç—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    filtered_candidates = []
    for article, stock, wh in candidates:
        state = status_map.get(article, "available")
        if state in ("archived", "disabled", "unavailable"):
            # –Ω–µ –≤–∫–ª—é—á–∞–µ–º
            continue
        filtered_candidates.append((article, stock, wh))

    candidates = filtered_candidates
# ============================================================

    stocks: list[dict] = []
    skipped_not_found = 0

    for article, stock, ozon_wh_id in candidates:
        stocks.append({
            "offer_id": article,
            "stock": stock,
            "warehouse_id": ozon_wh_id,
        })

    report_rows = [
        {
            "name": names_by_article.get(s["offer_id"], ""),
            "article": s["offer_id"],
            "stock": s["stock"],
        }
        for s in stocks
    ]

    return stocks, skipped_not_found, report_rows



# ---------------------
#  –û–¢–ß–Å–¢ –í TELEGRAM
# ---------------------

def _send_stock_report_file(report_rows: list[dict]) -> None:
    if not report_rows:
        print("[STOCK] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî CSV –Ω–µ —Å–æ–∑–¥–∞–Ω.")
        return

    fd, tmp_path = tempfile.mkstemp(prefix="ozon_stock_", suffix=".csv")
    os.close(fd)

    try:
        with open(tmp_path, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(["‚Ññ", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ê—Ä—Ç–∏–∫—É–ª", "–ö–æ–ª-–≤–æ"])

            for idx, row in enumerate(report_rows, start=1):
                writer.writerow([
                    idx,
                    row["name"],
                    row["article"],
                    row["stock"],
                ])

        ok = send_telegram_document(tmp_path, caption="–û—Å—Ç–∞—Ç–∫–∏ Ozon (–æ–±–∞ –∫–∞–±–∏–Ω–µ—Ç–∞)")
        print(f"[STOCK] CSV –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {tmp_path}" if ok else f"[STOCK] –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ CSV: {tmp_path}")

    finally:
        try:
            os.remove(tmp_path)
        except:
            pass


# ---------------------
#  –û–°–ù–û–í–ù–û–ô –ö–û–î
# ---------------------

def main(dry_run: bool | None = None) -> None:
    if dry_run is None:
        dry_run = DRY_RUN

    print(f"[STOCK] DRY_RUN={dry_run}")

    try:
        send_telegram_message(f"üîÅ CRON: –∑–∞–ø—É—Å–∫ sync_stock (–æ—Å—Ç–∞—Ç–∫–∏), DRY_RUN={dry_run}")
    except Exception:
        pass

    stocks, skipped, report_rows = build_ozon_stocks_from_ms()

    print(f"[STOCK] –ü—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ—Ç –≤ Ozon): {skipped}")
    print(f"[STOCK] –ü–µ—Ä–µ–¥–∞—ë–º –≤ Ozon –ø–æ–∑–∏—Ü–∏–π: {len(stocks)}")
    print(f"[STOCK] –°—Ç—Ä–æ–∫ –≤ –æ—Ç—á—ë—Ç–µ CSV: {len(report_rows)}")

    _send_stock_report_file(report_rows)

    if dry_run:
        print("[STOCK] DRY_RUN: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ Ozon –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è.")
        return

    if not stocks:
        print("[STOCK] –ù–µ—Ç –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.")
        return

    # –ü–µ—Ä–≤—ã–π –∫–∞–±–∏–Ω–µ—Ç (Auto-MiX)
    update_stocks(stocks)

    # –í—Ç–æ—Ä–æ–π –∫–∞–±–∏–Ω–µ—Ç (Trail Gear)
    try:
        update_stocks_ozon2(stocks)
    except Exception as e:
        msg = f"[STOCK] –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤ –≤–æ –≤—Ç–æ—Ä–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ Ozon: {e!r}"
        print(msg)
        try:
            send_telegram_message(msg)
        except:
            pass


if __name__ == "__main__":
    main()
